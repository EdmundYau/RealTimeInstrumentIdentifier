{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n",
      "TensorFlow is using: \n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization, Add\n",
    "from tqdm import tqdm\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"TensorFlow is using:\", tf.test.gpu_device_name())\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def load_data(spectrogram_dir, label_dir):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "\n",
    "    # Load spectrograms\n",
    "    spectrogram_files = sorted(os.listdir(spectrogram_dir))\n",
    "    label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "    total_files = len(spectrogram_files)  \n",
    "\n",
    "    for spec_file, label_file in tqdm(zip(spectrogram_files, label_files), \n",
    "                                      total=total_files, \n",
    "                                      desc=\"Loading Data\", \n",
    "                                      unit=\"file\"):\n",
    "        \n",
    "        spectrogram = np.load(os.path.join(spectrogram_dir, spec_file))  \n",
    "        label = np.load(os.path.join(label_dir, label_file)).T \n",
    "\n",
    "        # Pad or trim labels\n",
    "        T_spec = spectrogram.shape[0]  \n",
    "        T_label = label.shape[0]      \n",
    "        if T_label < T_spec:\n",
    "            diff = T_spec - T_label\n",
    "            label = np.pad(label, ((0, diff), (0, 0)), mode='constant')\n",
    "        elif T_label > T_spec:\n",
    "            label = label[:T_spec]\n",
    "            \n",
    "        spectrograms.append(spectrogram)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.vstack(spectrograms)  \n",
    "    Y = np.vstack(labels)     \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 270/270 [00:01<00:00, 217.78file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (65912, 128, 87, 1) Y_train: (65912, 129)\n"
     ]
    }
   ],
   "source": [
    "# ========= USING VALIDATION SET FOR SMALLER DATA ==========\n",
    "\n",
    "X_train, Y_train = load_data(\"spectrograms_validation\", \"primary_labels_validation\") \n",
    "X_train = np.expand_dims(X_train, axis=-1)  \n",
    "print(\"X_train:\", X_train.shape, \"Y_train:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739002793.197008    1175 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 87, 1)),  # Shape of each input spectrogram\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(129, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and binary accuracy as the metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 00:19:56.936896: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2935984128 exceeds 10% of free system memory.\n",
      "2025-02-08 00:19:58.485076: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2935984128 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739002800.517272    1602 service.cc:148] XLA service 0x7f914800ef00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739002800.517330    1602 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2025-02-08 00:20:00.566275: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1739002800.840929    1602 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   6/1030\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - binary_accuracy: 0.6051 - loss: 0.8345 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739002805.890111    1602 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - binary_accuracy: 0.9470 - loss: 0.1512\n",
      "Epoch 2/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9659 - loss: 0.0994\n",
      "Epoch 3/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9694 - loss: 0.0859\n",
      "Epoch 4/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9728 - loss: 0.0746\n",
      "Epoch 5/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9756 - loss: 0.0666\n",
      "Epoch 6/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9778 - loss: 0.0602\n",
      "Epoch 7/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9793 - loss: 0.0559\n",
      "Epoch 8/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9807 - loss: 0.0522\n",
      "Epoch 9/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9816 - loss: 0.0497\n",
      "Epoch 10/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9825 - loss: 0.0474\n",
      "Epoch 11/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9831 - loss: 0.0454\n",
      "Epoch 12/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9837 - loss: 0.0437\n",
      "Epoch 13/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - binary_accuracy: 0.9842 - loss: 0.0425\n",
      "Epoch 14/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - binary_accuracy: 0.9846 - loss: 0.0413\n",
      "Epoch 15/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - binary_accuracy: 0.9850 - loss: 0.0402\n",
      "Epoch 16/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9853 - loss: 0.0390\n",
      "Epoch 17/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - binary_accuracy: 0.9856 - loss: 0.0385\n",
      "Epoch 18/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9859 - loss: 0.0373\n",
      "Epoch 19/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - binary_accuracy: 0.9862 - loss: 0.0367\n",
      "Epoch 20/20\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - binary_accuracy: 0.9864 - loss: 0.0361\n",
      "Final Loss: 0.0364, Final Accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, Y_train, batch_size=64, epochs=20, verbose=1)\n",
    "\n",
    "# Final loss & accuracy\n",
    "final_loss = history.history['loss'][-1]\n",
    "final_accuracy = history.history['binary_accuracy'][-1]\n",
    "print(f\"Final Loss: {final_loss:.4f}, Final Accuracy: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 00:28:46.864360: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2935984128 exceeds 10% of free system memory.\n",
      "2025-02-08 00:28:48.572777: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2935984128 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2056/2060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 00:29:03.744748: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_88_0', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2060/2060\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step\n",
      "Precision: 0.8948\n",
      "Recall: 0.8541\n",
      "F1-Score: 0.8631\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "Y_pred = model.predict(X_train)\n",
    "\n",
    "# Convert to binary (threshold the probabilities)\n",
    "threshold = 0.5\n",
    "Y_pred_binary = (Y_pred > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(Y_train, Y_pred_binary, average='samples', zero_division=0)\n",
    "recall = recall_score(Y_train, Y_pred_binary, average='samples', zero_division=0)\n",
    "f1 = f1_score(Y_train, Y_pred_binary, average='samples', zero_division=0)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 151/151 [00:01<00:00, 90.89file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1234/1234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step\n",
      "Test Precision: 0.5462\n",
      "Test Recall: 0.3136\n",
      "Test F1-Score: 0.3787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test, Y_test = load_data(\"spectrograms_test\", \"primary_labels_test\")  \n",
    "X_test = np.expand_dims(X_test, axis=-1)  \n",
    "\n",
    "Y_pred_test = model.predict(X_test)\n",
    "Y_pred_test_binary = (Y_pred_test > 0.5).astype(int)\n",
    "\n",
    "precision_test = precision_score(Y_test, Y_pred_test_binary, average='samples', zero_division=0)\n",
    "recall_test = recall_score(Y_test, Y_pred_test_binary, average='samples', zero_division=0)\n",
    "f1_test = f1_score(Y_test, Y_pred_test_binary, average='samples', zero_division=0)\n",
    "\n",
    "print(f\"Test Precision: {precision_test:.4f}\")\n",
    "print(f\"Test Recall: {recall_test:.4f}\")\n",
    "print(f\"Test F1-Score: {f1_test:.4f}\")\n",
    "\n",
    "# F1-score on different set not so good, likely overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
